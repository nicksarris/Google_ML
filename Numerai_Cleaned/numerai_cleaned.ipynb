{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "__author__ = 'Nick Sarris (ngs5st)'\n",
    "\n",
    "import umap\n",
    "import time\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "import operator\n",
    "import random\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.base import TransformerMixin\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "\n",
    "print(os.listdir(\"./data\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "def seed_everything(seed=1235):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "seed_everything(1235)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "print(\"Loading Data ...\")\n",
    "\n",
    "directory = \"./data/\"\n",
    "train_df = pd.read_csv(directory + 'numerai_training_data.csv')\n",
    "test_df = pd.read_csv(directory + 'numerai_tournament_data.csv')\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "print(\"Initial Processing ...\")\n",
    "\n",
    "ids = test_df['id'].values\n",
    "labels = pd.DataFrame(train_df['target_kazutsugi'].values)\n",
    "cols_to_drop = [\"id\", \"era\", \"data_type\", \"target_kazutsugi\"]\n",
    "\n",
    "for col in cols_to_drop:\n",
    "    train_df.drop(col, inplace=True, axis=1)\n",
    "    if col in test_df.columns:\n",
    "        test_df.drop(col, inplace=True, axis=1)\n",
    "        \n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SelectFeatures(X, y, cutoff):\n",
    "\n",
    "    clf = xgb.XGBClassifier(n_estimators=20, base_score=0.005)\n",
    "    clf.fit(X, y)\n",
    "\n",
    "    column_importance = clf.feature_importances_\n",
    "    columns = X.columns\n",
    "    column_dict = dict()\n",
    "    column_list = []\n",
    "\n",
    "    for row, value in zip(columns, column_importance):\n",
    "        column_dict[row] = value\n",
    "\n",
    "    column_dict = sorted(column_dict.items(), key=operator.itemgetter(1))\n",
    "    for row, value in column_dict:\n",
    "        print ('Feature:', row,'| Importance:', value)\n",
    "        if value > cutoff:\n",
    "            list.append(column_list, row)\n",
    "\n",
    "    return column_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "print(\"Specifying Initial Features ...\")\n",
    "\n",
    "combined_features = []\n",
    "attributes = [\"strength\", \"dexterity\", \"constitution\", \"intelligence\", \"wisdom\", \"charisma\"]\n",
    "\n",
    "for attribute in attributes:\n",
    "    print(\"\\nTraining on Attribute: {}\".format(attribute.capitalize()))\n",
    "    feature_df = train_df[[col for col in train_df.columns if attribute in col]]\n",
    "    important_cols = SelectFeatures(feature_df, labels, 0.01)\n",
    "    combined_features += important_cols\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "print(\"Limit Features ...\")\n",
    "\n",
    "train_feats = train_df[combined_features]\n",
    "test_feats = test_df[combined_features]\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GenerateLinear(TransformerMixin):\n",
    "\n",
    "    def __init__(self, n_neighbors, max_elts=None):\n",
    "        self.rnd = 2018\n",
    "        self.n = n_neighbors\n",
    "        self.max_elts = max_elts\n",
    "        self.verbose = True\n",
    "        self.neighbors = []\n",
    "        self.clfs = []\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        random.seed(self.rnd)\n",
    "        if self.max_elts == None:\n",
    "            self.max_elts = len(X.columns)\n",
    "\n",
    "        list_vars = list(X.columns)\n",
    "        random.shuffle(list_vars)\n",
    "        lastscores = (np.zeros(self.n) + 1e15)\n",
    "        for elt in list_vars:\n",
    "            self.neighbors.append([elt])\n",
    "\n",
    "        for elt in list_vars:\n",
    "            index = 0\n",
    "            scores = []\n",
    "            print('Currently Estimating {}'.format(elt))\n",
    "\n",
    "            for elt2 in self.neighbors:\n",
    "                if len(elt2) < self.max_elts:\n",
    "                    clf1 = LinearRegression(fit_intercept=False,\n",
    "                        normalize=True, copy_X=True, n_jobs=-1)\n",
    "                    clf1.fit(X[elt2 + [elt]], y)\n",
    "                    scores.append(mean_squared_error(y, clf1.predict(X[elt2 + [elt]])))\n",
    "                    index += 1\n",
    "                else:\n",
    "                    scores.append(lastscores[index])\n",
    "                    index += 1\n",
    "\n",
    "            gains = lastscores - scores\n",
    "            temp = gains.argmax()\n",
    "            lastscores[temp] = scores[temp]\n",
    "            self.neighbors[temp].append(elt)\n",
    "\n",
    "        index = 0\n",
    "        for elt in self.neighbors:\n",
    "            clf = LinearRegression(fit_intercept=False,\n",
    "                normalize=True, copy_X=True, n_jobs=-1)\n",
    "            clf.fit(X[elt], y)\n",
    "            self.clfs.append(clf)\n",
    "            if self.verbose:\n",
    "                print(index, lastscores[index], elt)\n",
    "            index += 1\n",
    "\n",
    "    def transform(self, X):\n",
    "        index = 0\n",
    "        for elt in self.neighbors:\n",
    "            X['neighbor' + str(index)] = \\\n",
    "                self.clfs[index].predict(X[elt])\n",
    "            index += 1\n",
    "        return X\n",
    "\n",
    "    def fit_transform(self, X, y=None, **fit_params):\n",
    "        self.fit(X,y)\n",
    "        return self.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "print(\"Generate Linear Neighbors ...\")\n",
    "\n",
    "linear_feats = GenerateLinear(n_neighbors=train_feats.shape[1], max_elts=2)\n",
    "train_feats = linear_feats.fit_transform(train_feats, labels)\n",
    "test_feats = linear_feats.transform(test_feats)\n",
    "important_cols = SelectFeatures(train_feats, labels, 0)\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "print(\"Scaling Columns ...\")\n",
    "\n",
    "train_feats = train_feats[important_cols]\n",
    "test_feats = test_feats[important_cols]\n",
    "pipeline = Pipeline([('scaler', MinMaxScaler())])\n",
    "poly_train = pd.DataFrame(pipeline.fit_transform(train_feats))\n",
    "poly_test = pd.DataFrame(pipeline.transform(test_feats))\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GeneratePCA():\n",
    "\n",
    "    def __init__(self):\n",
    "        self.n_comp = 5\n",
    "        self.pca = PCA(n_components=self.n_comp)\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        return self.pca.fit(X)\n",
    "\n",
    "    def transform(self, X, output):\n",
    "        pca_results = self.pca.transform(\n",
    "            normalize(X, axis=0))\n",
    "        for i in range(0, self.n_comp):\n",
    "            output['pca_' + str(i)] = pca_results[:, i]\n",
    "        return output\n",
    "\n",
    "    def fit_transform(self, X, output):\n",
    "        self.pca.fit(X)\n",
    "        pca_results = self.pca.transform(\n",
    "            normalize(X, axis=0))\n",
    "        for i in range(0, self.n_comp):\n",
    "            output['pca_' + str(i)] = pca_results[:, i]\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "print(\"Generating PCA ...\")\n",
    "\n",
    "pca_feats = GeneratePCA()\n",
    "train_feats = pca_feats.fit_transform(train_feats, poly_train)\n",
    "test_feats = pca_feats.transform(test_feats, poly_test)\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class XgbWrapper(object):\n",
    "    \n",
    "    def __init__(self, seed=2018, params=None):\n",
    "        self.param = params\n",
    "        self.param['seed'] = seed\n",
    "        self.nrounds = params.pop('nrounds', 200)\n",
    "\n",
    "    def train(self, x_train, y_train):\n",
    "        dtrain = xgb.DMatrix(x_train, label=y_train)\n",
    "        self.gbdt = xgb.train(self.param, dtrain, self.nrounds)\n",
    "\n",
    "    def predict(self, x):\n",
    "        return self.gbdt.predict(xgb.DMatrix(x))\n",
    "    \n",
    "def get_oof(clf, ntrain, ntest, kf, train, labels, test):\n",
    "    \n",
    "    oof_train = np.zeros((ntrain,))\n",
    "    oof_test = np.zeros((ntest,))\n",
    "    oof_test_skf = np.empty((5, ntest))\n",
    "\n",
    "    for i, (train_index, test_index) in enumerate(kf):\n",
    "        x_tr = train[train_index]\n",
    "        y_tr = labels[train_index]\n",
    "        x_te = train[test_index]\n",
    "\n",
    "        clf.train(x_tr, y_tr)\n",
    "        oof_train[test_index] = clf.predict(x_te)\n",
    "        oof_test_skf[i, :] = clf.predict(test)\n",
    "\n",
    "    oof_test[:] = oof_test_skf.mean(axis=0)\n",
    "    return oof_train.reshape(-1, 1), oof_test.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "print(\"Training First Layer ...\")\n",
    "\n",
    "train = np.array(train_feats)\n",
    "test = np.array(test_feats)\n",
    "labels = np.array(labels)\n",
    "\n",
    "ntrain = train.shape[0]\n",
    "ntest = test.shape[0]\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=2017).split(train)\n",
    "\n",
    "xgb_params = {}\n",
    "xgb_params[\"objective\"] = \"binary:logistic\"\n",
    "xgb_params[\"eta\"] = 0.05\n",
    "xgb_params[\"subsample\"] = 0.7\n",
    "xgb_params[\"silent\"] = 1\n",
    "xgb_params[\"max_depth\"] = 6\n",
    "xgb_params[\"min_child_weight\"] = 5\n",
    "xgb_params['eval_metric'] = 'logloss'\n",
    "\n",
    "xg = XgbWrapper(seed=2018, params=xgb_params)\n",
    "xg_oof_train, xg_oof_test = get_oof(xg, ntrain, ntest, kf, train, labels, test)\n",
    "#print(\"XG-CV: {}\".format(roc_auc_score(labels, xg_oof_train)))\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "print(\"Generate Submission ...\")\n",
    "\n",
    "submission = pd.DataFrame()\n",
    "submission['id'] = ids\n",
    "submission['prediction_kazutsugi'] = xg_oof_test\n",
    "submission.to_csv(\"output_predictions.csv\", index=False)\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
