{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "__author__ = 'Nick Sarris (ngs5st)'\n",
    "\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "\n",
    "from datetime import datetime\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import KFold\n",
    "from scipy.stats import skew, boxcox\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import itertools\n",
    "\n",
    "print(os.listdir(\"./data\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "def seed_everything(seed=1235):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "seed_everything(1235)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "print(\"Loading Data ...\")\n",
    "\n",
    "directory = \"./data/\"\n",
    "train_df = pd.read_csv(directory + 'train.csv')\n",
    "test_df = pd.read_csv(directory + 'test.csv')\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(charcode):\n",
    "    r = 0\n",
    "    ln = len(str(charcode))\n",
    "    for i in range(ln):\n",
    "        r += (ord(str(charcode)[i]) - ord('A') + 1) * 26 ** (ln - i - 1)\n",
    "    return r\n",
    "\n",
    "def mungeskewed(train, test, numeric_feats):\n",
    "    ntrain = train.shape[0]\n",
    "    test['loss'] = 0\n",
    "    train_test = pd.concat((train, test)).reset_index(drop=True)\n",
    "    skewed_feats = train[numeric_feats].apply(lambda x: skew(x.dropna()))\n",
    "    skewed_feats = skewed_feats[skewed_feats > 0.25]\n",
    "    skewed_feats = skewed_feats.index\n",
    "\n",
    "    for feats in skewed_feats:\n",
    "        train_test[feats] = train_test[feats] + 1\n",
    "        train_test[feats], lam = boxcox(train_test[feats])\n",
    "        \n",
    "    return train_test, ntrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "print(\"Feature Engineering [1] ...\")\n",
    "\n",
    "COMB_FEATURE = 'cat80,cat87,cat57,cat12,cat79,cat10,cat7,cat89,cat2,cat72,' \\\n",
    "               'cat81,cat11,cat1,cat13,cat9,cat3,cat16,cat90,cat23,cat36,' \\\n",
    "               'cat73,cat103,cat40,cat28,cat111,cat6,cat76,cat50,cat5,' \\\n",
    "               'cat4,cat14,cat38,cat24,cat82,cat25'.split(',')\n",
    "\n",
    "numeric_feats = [x for x in train_df.columns[1:-1] if 'cont' in x]\n",
    "train_test, ntrain = mungeskewed(train_df, test_df, numeric_feats)\n",
    "\n",
    "for comb in itertools.combinations(COMB_FEATURE, 2):\n",
    "    feat = comb[0] + \"_\" + comb[1]\n",
    "    train_test[feat] = train_test[comb[0]] + train_test[comb[1]]\n",
    "    train_test[feat] = train_test[feat].apply(encode)\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "print(\"Feature Engineering [2] ...\")\n",
    "\n",
    "categorical_feats = [x for x in train_df.columns[1:-1] if 'cat' in x]\n",
    "\n",
    "for col in categorical_feats:\n",
    "    train_test[col] = train_test[col].apply(encode)\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "print(\"Scaling Features ...\")\n",
    "\n",
    "ss = StandardScaler()\n",
    "train_test[numeric_feats] = ss.fit_transform(train_test[numeric_feats].values)\n",
    "\n",
    "train = train_test.iloc[:ntrain, :].copy()\n",
    "test = train_test.iloc[ntrain:, :].copy()\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "print(\"Splitting Data ...\")\n",
    "\n",
    "shift = 200\n",
    "ids = pd.read_csv(directory + 'test.csv')['id']\n",
    "train_x = np.array(train.drop(['loss','id'], axis=1))\n",
    "labels = np.array(np.log(train['loss'] + shift))\n",
    "test_x = np.array(test.drop(['loss','id'], axis=1))\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "print(\"Establishing Parameters ...\")\n",
    "\n",
    "xgb_params = {}\n",
    "xgb_params[\"seed\"] = 0\n",
    "xgb_params[\"colsample_bytree\"] = 0.7\n",
    "xgb_params[\"silent\"] = 1\n",
    "xgb_params[\"subsample\"] = 0.7\n",
    "xgb_params[\"learning_rate\"] = 0.03\n",
    "xgb_params[\"objective\"] = 'reg:linear'\n",
    "xgb_params[\"max_depth\"] = 12\n",
    "xgb_params[\"min_child_weight\"] = 100\n",
    "xgb_params[\"booster\"] = 'gbtree'\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fair_obj(preds, dtrain):\n",
    "    labels = dtrain.get_label()\n",
    "    x = (preds - labels)\n",
    "    den = abs(x) + 2\n",
    "    grad = 2 * x / (den)\n",
    "    hess = 4 / (den * den)\n",
    "    return grad, hess\n",
    "\n",
    "def xg_eval_mae(yhat, dtrain):\n",
    "    y = dtrain.get_label()\n",
    "    return 'mae', mean_absolute_error(\n",
    "        np.exp(y)-shift, np.exp(yhat)-shift)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "print(\"Training Model ...\")\n",
    "\n",
    "cv_sum = 0\n",
    "n_folds = 10\n",
    "fpred = []\n",
    "xgb_rounds = []\n",
    "\n",
    "kf = KFold(n_splits=n_folds, shuffle=True, random_state=2018).split(train_x)\n",
    "dtest = xgb.DMatrix(test_x)\n",
    "\n",
    "for i, (train_index, test_index) in enumerate(kf):\n",
    "    x_tr = train_x[train_index]\n",
    "    y_tr = labels[train_index]\n",
    "    x_te = train_x[test_index]\n",
    "    y_te = labels[test_index]\n",
    "\n",
    "    dtrain = xgb.DMatrix(x_tr, label=y_tr)\n",
    "    dvalid = xgb.DMatrix(x_te, label=y_te)\n",
    "    watchlist = [(dtrain, 'train'), (dvalid, 'eval')]\n",
    "\n",
    "    clf = xgb.train(xgb_params, dtrain, 10000, watchlist,\n",
    "                    early_stopping_rounds=50, obj=fair_obj,\n",
    "                    feval=xg_eval_mae, verbose_eval=20)\n",
    "\n",
    "    xgb_rounds.append(clf.best_iteration)\n",
    "    scores_val = clf.predict(dvalid, ntree_limit=clf.best_ntree_limit)\n",
    "    cv_score = mean_absolute_error(np.exp(y_te), np.exp(scores_val))\n",
    "    y_pred = np.exp(clf.predict(dtest, ntree_limit=clf.best_ntree_limit)) - shift\n",
    "    print(\"XG-CV: {}\".format(mean_absolute_error(np.exp(y_te), np.exp(scores_val))))\n",
    "\n",
    "    if i > 0:\n",
    "        fpred = pred + y_pred\n",
    "    else:\n",
    "        fpred = y_pred\n",
    "                             \n",
    "    pred = fpred\n",
    "    cv_sum = cv_sum + cv_score\n",
    "\n",
    "mpred = pred / n_folds\n",
    "score = cv_sum / n_folds\n",
    "print('Average XG-CV: {}'.format(score))\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "print(\"Generate Submission ...\")\n",
    "\n",
    "submission = pd.DataFrame()\n",
    "submission['id'] = ids\n",
    "submission['loss'] = mpred\n",
    "submission.to_csv(\"output_data.csv\", index=False)\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
