{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "__author__ = 'Nick Sarris (ngs5st)'\n",
    "\n",
    "import os\n",
    "import time\n",
    "import gc\n",
    "import sys\n",
    "import gzip\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import shutil\n",
    "import pickle\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils import data\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import KFold\n",
    "from random import shuffle\n",
    "\n",
    "from pytorch_pretrained_bert import convert_tf_checkpoint_to_pytorch\n",
    "from pytorch_pretrained_bert import BertTokenizer, BertConfig\n",
    "from pytorch_pretrained_bert.modeling import BertPreTrainedModel, BertModel\n",
    "from pytorch_pretrained_bert.optimization import BertAdam\n",
    "\n",
    "from keras.preprocessing import text, sequence\n",
    "from tqdm._tqdm_notebook import tqdm_notebook as tqdm\n",
    "from nltk.tokenize.treebank import TreebankWordTokenizer\n",
    "\n",
    "print(os.listdir(\"./data/\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed=1235):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "seed_everything(1235)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "print(\"Establishing Global Variables ...\")\n",
    "\n",
    "# Data Directory\n",
    "directory = './data/'\n",
    "\n",
    "# Torch Device\n",
    "device = torch.device('cuda')\n",
    "\n",
    "# Model Parameters\n",
    "max_length = 220\n",
    "batch_size = 32\n",
    "n_epochs = 2\n",
    "accumulation_steps = 1\n",
    "\n",
    "# Model/Split Seed/Parameters\n",
    "# Change model_seed with every new/different model\n",
    "# Keep split_seed the same throughout\n",
    "model_seed = 1234\n",
    "current_split = 0\n",
    "\n",
    "# Model File Paths\n",
    "TRAIN_FILE = directory + 'train.csv'\n",
    "TEST_FILE  = directory + 'test.csv'\n",
    "PROCESSED_FILE = 'train_seq.pickle'\n",
    "\n",
    "# Directory/BERT Paths\n",
    "WORK_DIR = directory\n",
    "BERT_MODEL_PATH = directory + 'uncased_L-12_H-768_A-12/'\n",
    "BERT_WEIGHT_PATH = 'bert_pytorch_model.bin'\n",
    "\n",
    "convert_tf_checkpoint_to_pytorch.convert_tf_checkpoint_to_pytorch(\n",
    "    BERT_MODEL_PATH + 'bert_model.ckpt',\n",
    "    BERT_MODEL_PATH + 'bert_config.json',\n",
    "    WORK_DIR + 'pytorch_model.bin')\n",
    "\n",
    "shutil.copyfile(BERT_MODEL_PATH + 'bert_config.json', WORK_DIR + 'bert_config.json')\n",
    "bert_config = BertConfig(BERT_MODEL_PATH + 'bert_config.json')\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_lines(example, max_seq_length,tokenizer):\n",
    "    \n",
    "    max_seq_length -= 2\n",
    "    all_tokens = []\n",
    "    longer = 0\n",
    "    \n",
    "    for text in tqdm(example):\n",
    "        tokens_a = tokenizer.tokenize(text)\n",
    "        if len(tokens_a)>max_seq_length:\n",
    "            tokens_a = tokens_a[:max_seq_length]\n",
    "            longer += 1\n",
    "        one_token = (tokenizer.convert_tokens_to_ids(\n",
    "            [\"[CLS]\"] + tokens_a + [\"[SEP]\"]) + [0] * (max_seq_length - len(tokens_a)))\n",
    "        all_tokens.append(one_token)\n",
    "    \n",
    "    return np.array(all_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "print(\"Processing Data ...\")\n",
    "\n",
    "bert_test = pd.read_csv(TEST_FILE)\n",
    "bert_test['comment_text'] = bert_test['comment_text'].astype(str) \n",
    "tokenizer = BertTokenizer.from_pretrained(BERT_MODEL_PATH, cache_dir=None,do_lower_case=True)\n",
    "bert_test_set = convert_lines(bert_test[\"comment_text\"].fillna(\"DUMMY_VALUE\"), max_length, tokenizer)\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyBertClassifier(BertPreTrainedModel):\n",
    "\n",
    "    def __init__(self, config, num_aux_targets):\n",
    "        super(MyBertClassifier, self).__init__(config)\n",
    "\n",
    "        self.bert = BertModel(config)\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        self.linear = nn.Linear(config.hidden_size, config.hidden_size)\n",
    "        self.linear_out = nn.Linear(config.hidden_size, 1)\n",
    "        self.linear_aux_out = nn.Linear(config.hidden_size, num_aux_targets)\n",
    "        self.apply(self.init_bert_weights)\n",
    "\n",
    "    def forward(self, input_ids, token_type_ids=None, attention_mask=None, labels=None):\n",
    "        \n",
    "        _, pooled_output = self.bert(input_ids, token_type_ids, attention_mask, output_all_encoded_layers=False)\n",
    "        pooled_output = self.dropout(pooled_output)\n",
    "        \n",
    "        h_conc_linear1  = F.relu(self.linear(pooled_output))\n",
    "        h_conc_linear1 = self.dropout(h_conc_linear1)\n",
    "    \n",
    "        hidden = pooled_output + h_conc_linear1        \n",
    "        result = self.linear_out(hidden)\n",
    "        aux_result = self.linear_aux_out(hidden)\n",
    "        out = torch.cat([result, aux_result], 1)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "print(\"Establishing DataLoaders ...\")\n",
    "\n",
    "device = torch.device('cuda')\n",
    "bert_test_size = len(bert_test_set)\n",
    "bert_test_dataset = torch.utils.data.TensorDataset(torch.tensor(bert_test_set, dtype=torch.long))\n",
    "bert_test_loader = torch.utils.data.DataLoader(bert_test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bert_model_inference(model_data, test_loader, test_size, batch_size):\n",
    "                    \n",
    "    device = torch.device('cuda')\n",
    "    model = MyBertClassifier(bert_config, 6)\n",
    "    model.load_state_dict(torch.load(model_data))\n",
    "    model.to(device)\n",
    "    \n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "    model.eval()\n",
    "    \n",
    "    test_preds = np.zeros((test_size))\n",
    "    tk = tqdm(enumerate(test_loader), total=len(test_loader), leave=False)\n",
    "\n",
    "    for i, (x_batch,) in tk:\n",
    "        y_pred = model(x_batch.to(device), attention_mask=(x_batch > 0).to(device), labels=None)\n",
    "        test_preds[i * batch_size: (i + 1) * batch_size] = y_pred[:,0].detach().cpu().squeeze().numpy()\n",
    "\n",
    "    test_preds = torch.sigmoid(torch.tensor(test_preds)).numpy().ravel()\n",
    "    return test_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "print(\"Inferencing Predictions ...\")\n",
    "\n",
    "preds = bert_model_inference(bert_model_data[0], bert_test_loader, bert_test_size, batch_size)\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "print(\"Generate Submission ...\")\n",
    "\n",
    "test = pd.read_csv(TEST_FILE)\n",
    "submission = pd.DataFrame.from_dict({'id': test['id'], 'prediction': preds})\n",
    "submission.to_csv('bert_submission.csv', index=False)\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
